{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import faiss\n",
    "from typing import Dict, List\n",
    "from functools import reduce\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import contextlib\n",
    "from distributed_faiss.client import IndexClient, IndexCfg, IndexState\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"\"\n",
    "os.environ[\"https_proxy\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_float32_array(num, dimention):\n",
    "    ret = np.zeros((num, dimention), np.float32)\n",
    "    step = 100000\n",
    "    for offset in tqdm(range(0, num, step)):\n",
    "        n = min(num - offset, step)\n",
    "        ret[offset:offset + n] = np.random.rand(n, dimention).astype(np.float32)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def timeit(comment):\n",
    "    print(f\"start {comment} ...\")\n",
    "    start = time()\n",
    "    yield\n",
    "    used = time() - start\n",
    "    print(comment, f\": {round(used, 2)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成 Enmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = DeepFace.represent(img_path=\"/home/featurize/work/vec/cfp-dataset/Data/Images/001/frontal/03.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = Path(\"/home/featurize/work/vec/cfp-dataset/Data/Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_embeddings = {}\n",
    "# for person_id in os.listdir(\"/home/featurize/work/vec/cfp-dataset/Data/Images\"):\n",
    "#     all_embeddings[person_id] = []\n",
    "#     for k, image_path in enumerate(Path(f\"/home/featurize/work/vec/cfp-dataset/Data/Images/{person_id}/frontal/\").glob(\"*.jpg\")):\n",
    "#         try:\n",
    "#             embedding = DeepFace.represent(img_path=image_path.as_posix())\n",
    "#         except ValueError:\n",
    "#             continue\n",
    "#         all_embeddings[person_id].append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path(\"./embeddings.pkl\").write_bytes(pickle.dumps(all_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat indexes 计算指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from socket import timeout\n",
    "\n",
    "\n",
    "class Index:\n",
    "\n",
    "    def prepare(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def add(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def query(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def clean(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "\n",
    "class EsIndex(Index):\n",
    "\n",
    "    def __init__(self, dimention):\n",
    "        self.dim = dimention\n",
    "        self.es = Elasticsearch(hosts=\"http://localhost:9200\", timeout=30)\n",
    "        self.index_name = \"vec-search-index\"\n",
    "\n",
    "    def prepare(self, embeddings):\n",
    "        print(\"delete index...\")\n",
    "        res = self.es.options(ignore_status=[400, 404], request_timeout=999).indices.delete(index=self.index_name, master_timeout=\"5m\")\n",
    "        print(\"create index...\")\n",
    "        index_body = {\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"vector\": {\n",
    "                        \"type\": \"dense_vector\",\n",
    "                        \"dims\": 512,\n",
    "                        \"index\": True,\n",
    "                        \"similarity\": \"l2_norm\"\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        self.es.indices.create(index=self.index_name, body=index_body, timeout=\"500m\", master_timeout=\"500m\")\n",
    "        with timeit(\"prepare embedding\"):\n",
    "            actions = [\n",
    "                {\n",
    "                    \"_index\": self.index_name,\n",
    "                    \"_id\": i,\n",
    "                    \"_source\": {\n",
    "                        \"vector\": embedding.tolist()\n",
    "                    }\n",
    "                }\n",
    "                for i, embedding in enumerate(tqdm(embeddings))\n",
    "            ]\n",
    "            print(\"start buck insert data...\")\n",
    "            helpers.bulk(self.es, actions)\n",
    "\n",
    "    def query(self, embeddings, num=10):\n",
    "        print(embeddings.shape)\n",
    "        res = self.es.knn_search(index=self.index_name, knn={\n",
    "            \"field\": \"vector\",\n",
    "            \"query_vector\": embeddings[0][:512],\n",
    "            \"k\": 10,\n",
    "            \"num_candidates\": 10,\n",
    "        }, source=[\"\"])\n",
    "        match_indices = []\n",
    "        for hit in res[\"hits\"][\"hits\"]:\n",
    "            match_indices.append(int(hit[\"_id\"]))\n",
    "        return np.array(match_indices)[np.newaxis, :]\n",
    "\n",
    "    def clean(self):\n",
    "        return\n",
    "\n",
    "\n",
    "class MilvusIndex(Index):\n",
    "\n",
    "    def __init__(self, dimention):\n",
    "        self.dim = dimention\n",
    "        connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "        utility.drop_collection(\"hello_milvus\")\n",
    "        fields = [\n",
    "            FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "            FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=self.dim)\n",
    "        ]\n",
    "        schema = CollectionSchema(fields, \"hello_milvus is the simplest demo to introduce the APIs\")\n",
    "        self.index = Collection(\"hello_milvus\", schema, consistency_level=\"Strong\")\n",
    "\n",
    "    def prepare(self, embeddings):\n",
    "        with timeit(\"prepare embedding\"):\n",
    "            for k in tqdm(range(0, embeddings.shape[0], 10000)):\n",
    "                entities = [\n",
    "                    [i+k for i in range(min(10000, len(embeddings) - k))],\n",
    "                    embeddings[k:k+10000, :],\n",
    "                ]\n",
    "                self.index.insert(entities)\n",
    "            self.index.create_index(\"embeddings\", {\n",
    "                \"index_type\": \"IVF_FLAT\",\n",
    "                \"metric_type\": \"L2\",\n",
    "                \"params\": {\"nlist\": 4096},\n",
    "            })\n",
    "            self.index.load()\n",
    "\n",
    "    def query(self, embeddings, num=10):\n",
    "        search_params = {\n",
    "            \"metric_type\": \"L2\",\n",
    "            \"params\": {\"nprobe\": 10},\n",
    "        }\n",
    "        res = self.index.search(embeddings, \"embeddings\", search_params, limit=num, output_fields=[\"pk\"])\n",
    "        pks = []\n",
    "        for hits in res:\n",
    "            for hit in hits:\n",
    "                pks.append(hit.entity.get('pk'))\n",
    "        return np.array(pks)[np.newaxis, :]\n",
    "\n",
    "    def clean(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class FaissIndex(Index):\n",
    "\n",
    "    def __init__(self, use_gpu=False, index_str=\"Flat\", dimention=512, distributed=False):\n",
    "        self.dimention = dimention\n",
    "        self.use_gpu = use_gpu\n",
    "        self.distributed = distributed\n",
    "        self.distributed_index_name = \"dd_index\"\n",
    "        self.index_str = index_str\n",
    "\n",
    "    def prepare(self, embeddings):\n",
    "        assert len(embeddings.shape) == 2\n",
    "        assert embeddings.shape[1] == self.dimention\n",
    "        if self.distributed:\n",
    "            self.index = IndexClient(\n",
    "                \"./faiss_distribute_config.txt\",\n",
    "            )\n",
    "            print(\"start to train index in distributed mode...\")\n",
    "            with timeit(\"train index in distributed mode\"):\n",
    "                self.index.create_index(self.distributed_index_name, IndexCfg(\n",
    "                    faiss_factory=\"OPQ16_64,IMI2x8,PQ8+16\",\n",
    "                    dim=self.dimention,\n",
    "                    index_storage_dir=\"/home/featurize/faiss_client_index\",\n",
    "                    metric=\"l2\"\n",
    "                ))\n",
    "                self.index.add_index_data(self.distributed_index_name, embeddings)\n",
    "                self.index.async_train(self.distributed_index_name)\n",
    "                for i in range(30):\n",
    "                    if self.index.get_state(self.distributed_index_name) != IndexState.TRAINED:\n",
    "                        sleep(1)\n",
    "                        continue\n",
    "        else:\n",
    "            self.index = faiss.index_factory(self.dimention, self.index_str)\n",
    "            if self.use_gpu:\n",
    "                res = faiss.StandardGpuResources()\n",
    "                self.index = faiss.index_cpu_to_gpu(res, 0, self.index)\n",
    "            if not self.index.is_trained:\n",
    "                print(\"start to train index...\")\n",
    "                with timeit(\"training time\"):\n",
    "                    self.index.train(embeddings)\n",
    "            print(\"start to add index...\")\n",
    "            print(embeddings.shape)\n",
    "            self.index.add(embeddings)\n",
    "\n",
    "    def query(self, embeddings, num=10):\n",
    "        if self.distributed:\n",
    "            D, I = self.index.search(embeddings, num, self.distributed_index_name, return_embeddings=False)\n",
    "        else:\n",
    "            D, I = self.index.search(embeddings, k=num)\n",
    "        return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDB:\n",
    "\n",
    "    def __init__(self, index: Index, embeddings: Dict[str, List[List[float]]], dimention=512):\n",
    "        # embeddings: {\"user_id\": [embedding, embedding, embedding]}\n",
    "        self.raw_embeddings = embeddings\n",
    "        self.dimention = dimention\n",
    "        self.user_lookup_table = []\n",
    "        self.index = index\n",
    "        for user_id, embeddings_list in self.raw_embeddings.items():\n",
    "            if len(embeddings_list) == 0:\n",
    "                continue\n",
    "            self.user_lookup_table += [user_id] * len(embeddings_list)\n",
    "\n",
    "    def build_index(self, number_of_extra_embedding):\n",
    "        face_embeddings = []\n",
    "        for user_id, embeddings_list in self.raw_embeddings.items():\n",
    "            if len(embeddings_list) == 0:\n",
    "                continue\n",
    "            face_embeddings.append(embeddings_list)\n",
    "\n",
    "        face_embeddings = np.concatenate(face_embeddings)[:, :self.dimention].astype(np.float32)\n",
    "        print(\"create random embeddings...\")\n",
    "        embeddings = random_float32_array(number_of_extra_embedding, self.dimention)\n",
    "        embeddings[:len(face_embeddings)] = face_embeddings\n",
    "        print(\"random embeddings created\")\n",
    "\n",
    "        print(\"embeddings shape: \", embeddings.shape)\n",
    "        print(\"user_lookup_table len: \", len(self.user_lookup_table))\n",
    "        self.index.prepare(embeddings)\n",
    "\n",
    "    def search(self, embeddings, num=10):\n",
    "        ret = self.index.query(embeddings[:, :self.dimention], num)\n",
    "        return ret\n",
    "\n",
    "    def test_add_embeddings(self, num):\n",
    "        start = time()\n",
    "        new_tokens = np.random.rand(num, self.dimention).astype(np.float32)\n",
    "        self.index.add(new_tokens)\n",
    "        time_used = time() - start\n",
    "        print(f\"add {num} tokens used {time_used}\")\n",
    "\n",
    "    def index2user_id(self, index):\n",
    "        if index >= len(self.user_lookup_table):\n",
    "            return \"unknown\"\n",
    "        else:\n",
    "            return self.user_lookup_table[index]\n",
    "\n",
    "    def evaluate_map(self):\n",
    "        # evaluate mAP\n",
    "        start = time()\n",
    "        k = np.max([len(x) for user_id, x in self.raw_embeddings.items()]).item()\n",
    "        scores = []\n",
    "        index_time = 0\n",
    "        for user_id, embeddings in tqdm(self.raw_embeddings.items()):\n",
    "            if len(embeddings) < 2:\n",
    "                continue\n",
    "            gt = [True] * (len(embeddings) - 1) + [False] * (k - len(embeddings))\n",
    "            for embedding in embeddings:\n",
    "                embedding = np.array(embedding, dtype=np.float32)[np.newaxis, :]\n",
    "                index_time += 1\n",
    "                results = self.search(embedding, num=k)[0]\n",
    "                results = results[1:]\n",
    "                results = [self.index2user_id(pred.item()) == user_id for pred in results]\n",
    "                score = average_precision_score(gt, results)\n",
    "                scores.append(score)\n",
    "        map = np.mean(scores)\n",
    "        time_used = time() - start\n",
    "        time_used / index_time * 1000\n",
    "        print(\"mAP: \", round(map, 4))\n",
    "        print(f\"performance: {round(time_used, 4)}s / 1kquerys\", )\n",
    "\n",
    "    def benchmark(self, embedding_num=None):\n",
    "        embedding_num = int(embedding_num)\n",
    "        if embedding_num is None:\n",
    "            print(f\"benchmark of original embeddings\")\n",
    "        else:\n",
    "            print(f\"benchmark of {embedding_num} embeddings\")\n",
    "        self.build_index(embedding_num)\n",
    "        self.evaluate_map()\n",
    "        self.test_add_embeddings(1000)\n",
    "        self.test_add_embeddings(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pickle.loads(Path(\"./embeddings.pkl\").read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = FaissIndex(index_str=\"OPQ16_64,IMI2x8,PQ8+16\", dimention=512)\n",
    "# index = FaissIndex(index_str=\"IVF4096,Flat\", dimention=512)\n",
    "# index = MilvusIndex(dimention=512)\n",
    "index = EsIndex(dimention=512)\n",
    "vdb = VectorDB(index, embeddings, dimention=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb.benchmark(1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 单样本预测\n",
    "# lookup_index = 220\n",
    "# res = vdb.search(vdb.embeddings[lookup_index:lookup_index+1], num=5)\n",
    "# print(\"Query user: \", vdb.user_lookup_table[lookup_index])\n",
    "# print(\"Top 10 res: \", \", \".join([vdb.user_lookup_table[k] for k in res[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('vec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fae64fd289db2aeb1580eea75929d72ffe231b11dfff168d2cf367c37f88984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
